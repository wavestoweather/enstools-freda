{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup\n",
    "\n",
    "At first, we create an instance of `UnstructuredGrid` which paritions the grid and handles all communication between individual processors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the petsc library, which returns an MPI communicator that is used everywhere\n",
    "from enstools.mpi import init_petsc, onRank0\n",
    "comm = init_petsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the grid object itself\n",
    "from enstools.mpi.grids import UnstructuredGrid\n",
    "from enstools.io import read\n",
    "grid_ds = read(\"/archive/meteo/external-models/dwd/grids/icon_grid_0016_R02B06_G.nc\")\n",
    "grid = UnstructuredGrid(grid_ds, overlap=25, comm=comm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.ncells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create some observations\n",
    "\n",
    "Observations are stored in the DWD feedback file format (http://www2.cosmo-model.org/content/model/documentation/core/cosmoFeedbackFileDefinition.pdf) for potantial later compatibility with the KENDA system and Leo's python tools. \n",
    "\n",
    "The class `FeedbackFile` implements functions to extract observations on pressure or model levels from a given model output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enstools.da.support import FeedbackFile, LevelType\n",
    "import getpass\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# create a temporal folder for all files we create here and later\n",
    "tmp_folder = f\"/project/meteo/scratch/{getpass.getuser()}/enstools-nda-test\"\n",
    "obs_file = f\"{tmp_folder}/tmp-obs.nc\"\n",
    "\n",
    "# we only do that on the first MPI rank\n",
    "if onRank0(comm):\n",
    "    # only create the folder once\n",
    "    os.makedirs(tmp_folder, exist_ok=True)\n",
    "        \n",
    "    # create a new feedback file object for the same grid as our grid object above\n",
    "    ff = FeedbackFile(filename=None, gridfile=grid_ds)\n",
    "    \n",
    "    # create two observations at the equator in model level 63 (about 500 hPa)\n",
    "    lon = np.asarray([-10.0, 0, 10.0]) * np.pi / 180.0\n",
    "    lat = np.asarray([0.0, 0.0, 0.0]) * np.pi / 180.0\n",
    "    nature_run_file = \"/archive/meteo/external-models/dwd/icon/oper/icon_oper_eps_gridded-global_rolling/202002/20200201T00/igaf2020020100.m040.grb\"\n",
    "    ff.add_observation_from_model_output(nature_run_file, variables=[\"T\"], error={\"T\": 1.0}, lon=lon, lat=lat, levels=[63], level_type=LevelType.MODEL_LEVEL)\n",
    "    \n",
    "    # modify the observations to get more impact\n",
    "    ff.data[\"obs\"].values += 5\n",
    "    \n",
    "    # store the observations to a temporal file\n",
    "    ff.write_to_file(obs_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a DA context\n",
    "\n",
    "The actual data assimilation is handled by the `DataAssimilation` class. Is has methods to read the state, partition observations into not overlapping subsets of observations, to run the actual data assimilation algorithm, and to store the state back to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the DA object. It makes use of the grid object for communication\n",
    "from enstools.da.nda import DataAssimilation\n",
    "da = DataAssimilation(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the load a number of ensemble members into memory. If the notebook crashs, increase the memory!\n",
    "da.load_state(\"/archive/meteo/external-models/dwd/icon/oper/icon_oper_eps_gridded-global_rolling/202002/20200201T00/igaf2020020100.m00[1-9].grb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the loaded state in order to run the algorithm multiple times. Attention: this double memory consumption!\n",
    "state_backup = da.backup_state()\n",
    "\n",
    "# the shape of the state variable is (n-cells, sum of all levels from all variables, n-members)\n",
    "state_backup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load observations. This step will also partition the observations into not overlapping subsets\n",
    "da.load_observations(obs_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the default algorithm. \n",
    "\n",
    "The `DataAssimilation` has a method `run`, that runs any algorithm that is provided. The algorithm is expected to have an `assimilate` methode and a `weights_for_gridpoint` methode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a copy of the Temperature field before running the algorithm\n",
    "t_before = da.get_state_variable(\"T\")\n",
    "print(t_before.shape)\n",
    "t_before_mean = t_before[:,63,:].mean(axis=1)\n",
    "print(t_before_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the algorithm for the first time will cause the JIT functions to be compiled\n",
    "from enstools.da.nda.algorithms.default import Default\n",
    "da.run(Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the results\n",
    "t_after_mean = da.get_state_variable(\"T\")[:,63,:].mean(axis=1)\n",
    "t_diff = t_after_mean - t_before_mean\n",
    "np.abs(t_diff).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the difference on a regular grid\n",
    "from enstools.misc import generate_coordinates\n",
    "from enstools.interpolation import nearest_neighbour\n",
    "from enstools.plot import contour\n",
    "\n",
    "plon, plat = generate_coordinates(0.2, lon_range=[-20, 20], lat_range=[-10, 10])\n",
    "f_interpol = nearest_neighbour(grid_ds[\"clon\"], grid_ds[\"clat\"], plon, plat, src_grid=\"unstructured\", dst_grid=\"regular\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_diff_interpol = f_interpol(t_diff.reshape(1, grid.ncells))\n",
    "contour(t_diff_interpol[0, ...], lon=plon, lat=plat, levels_center_on_zero=True, cmap=\"PuOr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the result into files\n",
    "\n",
    "For now, only storing the complete state is supported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.save_state(tmp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a new algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class for a new algorithm\n",
    "\n",
    "Have a look at `enstools.da.nda.algorithms.__init__.py` for the arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enstools.da.nda.algorithms.algorithm import Algorithm, model_equivalent, covariance\n",
    "from numba import jit, prange, i4, f4\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class FancyNew(Algorithm):\n",
    "\n",
    "    @staticmethod\n",
    "    @jit(\"void(f4[:,:,::1], i4[:,::1], f4[:,::1], i4[:,::1], i4[:,::1], i4[:,::1], f4[:,::1], i1[::1])\",\n",
    "         nopython=True, nogil=True, parallel=True,\n",
    "         locals={\"i_report\": i4, \"i_obs\": i4, \"i_radius\": i4, \"i_layer\": i4, \"i_points\": i4, \"i_cell\": i4,\n",
    "                 \"p_equivalent\": f4, \"denominator\": f4, \"p\": f4})\n",
    "    def assimilate(state: np.ndarray, state_map: np.ndarray,\n",
    "                   observations: np.ndarray, observation_type: np.ndarray, reports: np.ndarray,\n",
    "                   points_in_radius: np.ndarray, weights: np.ndarray, updated: np.ndarray):\n",
    "        \"\"\"\n",
    "        see Algorithm class for documentation of arguments.\n",
    "        \"\"\"\n",
    "        # temporal variables\n",
    "        n_varlayer = state.shape[1]\n",
    "        n_ens = state.shape[2]\n",
    "        n_inv = 1. / (n_ens - 1)\n",
    "        equivalent = np.empty(n_ens, dtype=np.float32)\n",
    "        deviation_equivalent_mean = np.empty(n_ens, dtype=np.float32)\n",
    "        innovation = np.empty(n_ens, dtype=np.float32)\n",
    "        random_error = np.empty(n_ens, dtype=np.float32)\n",
    "\n",
    "        # observations are processed one by one in the order that they are listed in the reports array\n",
    "        for i_report in range(reports.shape[0]):\n",
    "\n",
    "            # all observations in this report are located at this index within the local part of the grid.\n",
    "            grid_index = reports[i_report, 2]\n",
    "            assert grid_index != -1\n",
    "\n",
    "            # loop over all observations in this report\n",
    "            for i_obs in range(reports[i_report, 0], reports[i_report, 0] + reports[i_report, 1]):\n",
    "                # get model equivalents for the given observation and the mean which is later used for covariances\n",
    "                # for observation on model levels, model_equivalent returns just the corresponding gird cell.\n",
    "                model_equivalent(state, state_map, grid_index, observations, observation_type, i_obs,\n",
    "                                 equivalent, deviation_equivalent_mean)\n",
    "\n",
    "                # calculate innovation from observation value[i_obs, 0] and observation error[i_obs, 0]\n",
    "                random_error[:] = np.random.normal(0, observations[i_obs, 1], n_ens)\n",
    "                innovation[:] = observations[i_obs, 0] + random_error - equivalent\n",
    "\n",
    "                # calculate variance of model equivalent\n",
    "                p_equivalent = np.sum(deviation_equivalent_mean**2) * n_inv\n",
    "                denominator = 1.0 / (p_equivalent * observations[i_obs, 1]**2)\n",
    "\n",
    "                # loop over all grid cells and all variables that are within the localization radius\n",
    "                # This loop runs in parallel if NUMBA_NUM_THREADS is larger than 1.\n",
    "                i_points = reports[i_report, 3]\n",
    "                for i_radius in prange(points_in_radius.shape[1]):\n",
    "                    # the number of points for each observation is not constant. stop the loop as soon as we reach\n",
    "                    # a grid cell index of -1\n",
    "                    i_cell = points_in_radius[i_points, i_radius]\n",
    "                    if i_cell == -1:\n",
    "                        continue\n",
    "\n",
    "                    # mark the current point as updated. This will cause updates of overlapping areas between processors\n",
    "                    updated[i_cell] = 1\n",
    "\n",
    "                    # loop over all layers of the state, this is also a loop over all variables as variables are stacked\n",
    "                    # on top of each other in the state variable.\n",
    "                    for i_layer in range(n_varlayer):\n",
    "                        # calculate covariance between model equivalent and the current location in the state\n",
    "                        p = covariance(state, i_cell, i_layer, deviation_equivalent_mean) * weights[i_points, i_radius]\n",
    "\n",
    "                        # update the state at the current location\n",
    "                        for i_ens in range(n_ens):\n",
    "                            state[i_cell, i_layer, i_ens] += p * denominator * innovation[i_ens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the new FancyNew algorithm\n",
    "# at first, we restore the state from before running the Default algorithm\n",
    "da.restore_state(state_backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.run(FancyNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the results\n",
    "t_after_mean = da.get_state_variable(\"T\")[:,63,:].mean(axis=1)\n",
    "t_diff = t_after_mean - t_before_mean\n",
    "np.abs(t_diff).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_diff_interpol = f_interpol(t_diff.reshape(1, grid.ncells))\n",
    "contour(t_diff_interpol[0, ...], lon=plon, lat=plat, levels_center_on_zero=True, cmap=\"PuOr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enstools-nda",
   "language": "python",
   "name": "enstools-nda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
